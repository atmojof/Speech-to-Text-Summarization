{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import swagger_client\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG,\n",
    "        format=\"%(asctime)s %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_VERSION = \"2024-11-15\"\n",
    "\n",
    "# Your subscription key and region for the speech service\n",
    "SUBSCRIPTION_KEY = \"AZURE_KEY\"\n",
    "SERVICE_REGION = \"AZURE_SERVICE_REGION\"\n",
    "\n",
    "NAME = \"Simple transcription\"\n",
    "DESCRIPTION = \"Simple transcription description\"\n",
    "\n",
    "LOCALE = \"en-US\"\n",
    "RECORDINGS_BLOB_URI = \"https://smlbird.blob.core.windows.net/speechtotext/input/Recording 12.m4a\"\n",
    "\n",
    "# Provide the uri of a container with audio files for transcribing all of them\n",
    "# with a single request. At least 'read' and 'list' (rl) permissions are required.\n",
    "RECORDINGS_CONTAINER_URI = \"https://smlbird.blob.core.windows.net/speechtotext?sp=r&st=2025-01-21T10:43:59Z&se=2025-01-21T18:43:59Z&spr=https&sv=2022-11-02&sr=c&sig=Vcv5Zhz9hLKIJ0yM1AxcY52oNvLghj6ycPv%2FoHi4RKQ%3D\"\n",
    "\n",
    "# Set model information when doing transcription with custom models\n",
    "MODEL_REFERENCE = None  # guid of a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/21/2025 05:52:54 PM SE Asia Standard Time Starting transcription client...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomSpeechTranscriptionsApi' object has no attribute 'transcriptions_submit_with_http_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 178\u001b[0m\n\u001b[0;32m    174\u001b[0m             logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscription\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 136\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m()\u001b[0m\n\u001b[0;32m    127\u001b[0m transcription_definition \u001b[38;5;241m=\u001b[39m transcribe_from_single_blob(RECORDINGS_BLOB_URI, properties)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Uncomment this block to use custom models for transcription.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# transcription_definition = transcribe_with_custom_model(client, RECORDINGS_BLOB_URI, properties)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# uncomment the following block to enable and configure language identification prior to transcription\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Uncomment this block to transcribe all files from a container.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# transcription_definition = transcribe_from_container(RECORDINGS_CONTAINER_URI, properties)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m created_transcription, status, headers \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscriptions_submit_with_http_info\u001b[49m(transcription\u001b[38;5;241m=\u001b[39mtranscription_definition, api_version\u001b[38;5;241m=\u001b[39mAPI_VERSION)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# get the transcription Id from the location URI\u001b[39;00m\n\u001b[0;32m    139\u001b[0m transcription_id \u001b[38;5;241m=\u001b[39m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomSpeechTranscriptionsApi' object has no attribute 'transcriptions_submit_with_http_info'"
     ]
    }
   ],
   "source": [
    "def transcribe_from_single_blob(uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe a single audio file located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    transcription_definition = swagger_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_urls=[uri],\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n",
    "\n",
    "\n",
    "def transcribe_with_custom_model(client, uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe a single audio file located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    # Model information (ADAPTED_ACOUSTIC_ID and ADAPTED_LANGUAGE_ID) must be set above.\n",
    "    if MODEL_REFERENCE is None:\n",
    "        logging.error(\"Custom model ids must be set when using custom models\")\n",
    "        sys.exit()\n",
    "\n",
    "    model = {'self': f'{client.configuration.host}/models/{MODEL_REFERENCE}'}\n",
    "\n",
    "    transcription_definition = swagger_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_urls=[uri],\n",
    "        model=model,\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n",
    "\n",
    "\n",
    "def transcribe_from_container(uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe all files in the container located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    transcription_definition = swagger_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_container_url=uri,\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n",
    "\n",
    "\n",
    "def _paginate(api, paginated_object):\n",
    "    \"\"\"\n",
    "    The autogenerated client does not support pagination. This function returns a generator over\n",
    "    all items of the array that the paginated object `paginated_object` is part of.\n",
    "    \"\"\"\n",
    "    yield from paginated_object.values\n",
    "    typename = type(paginated_object).__name__\n",
    "    auth_settings = [\"api_key\"]\n",
    "    while paginated_object.next_link:\n",
    "        link = paginated_object.next_link[len(api.api_client.configuration.host):]\n",
    "        paginated_object, status, headers = api.api_client.call_api(link, \"GET\",\n",
    "            response_type=typename, auth_settings=auth_settings)\n",
    "\n",
    "        if status == 200:\n",
    "            yield from paginated_object.values\n",
    "        else:\n",
    "            raise Exception(f\"could not receive paginated data: status {status}\")\n",
    "\n",
    "\n",
    "def delete_all_transcriptions(api):\n",
    "    \"\"\"\n",
    "    Delete all transcriptions associated with your speech resource.\n",
    "    \"\"\"\n",
    "    logging.info(\"Deleting all existing completed transcriptions.\")\n",
    "\n",
    "    # get all transcriptions for the subscription\n",
    "    transcriptions = list(_paginate(api, api.get_transcriptions()))\n",
    "\n",
    "    # Delete all pre-existing completed transcriptions.\n",
    "    # If transcriptions are still running or not started, they will not be deleted.\n",
    "    for transcription in transcriptions:\n",
    "        transcription_id = transcription._self.split('/')[-1]\n",
    "        logging.debug(f\"Deleting transcription with id {transcription_id}\")\n",
    "        try:\n",
    "            api.delete_transcription(transcription_id)\n",
    "        except swagger_client.rest.ApiException as exc:\n",
    "            logging.error(f\"Could not delete transcription {transcription_id}: {exc}\")\n",
    "\n",
    "\n",
    "def transcribe():\n",
    "    logging.info(\"Starting transcription client...\")\n",
    "\n",
    "    # configure API key authorization: subscription_key\n",
    "    configuration = swagger_client.Configuration()\n",
    "    configuration.api_key[\"Ocp-Apim-Subscription-Key\"] = SUBSCRIPTION_KEY\n",
    "    configuration.host = f\"https://{SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext\"\n",
    "\n",
    "    # create the client object and authenticate\n",
    "    client = swagger_client.ApiClient(configuration)\n",
    "\n",
    "    # create an instance of the transcription api class\n",
    "    api = swagger_client.CustomSpeechTranscriptionsApi(api_client=client)\n",
    "\n",
    "    # Specify transcription properties by passing a dict to the properties parameter. See\n",
    "    # https://learn.microsoft.com/azure/cognitive-services/speech-service/batch-transcription-create?pivots=rest-api#request-configuration-options\n",
    "    # for supported parameters.\n",
    "    properties = swagger_client.TranscriptionProperties(6)\n",
    "    # properties.word_level_timestamps_enabled = True\n",
    "    # properties.display_form_word_level_timestamps_enabled = True\n",
    "    # properties.punctuation_mode = \"DictatedAndAutomatic\"\n",
    "    # properties.profanity_filter_mode = \"Masked\"\n",
    "    # properties.destination_container_url = \"<SAS Uri with at least write (w) permissions for an Azure Storage blob container that results should be written to>\"\n",
    "\n",
    "    # uncomment the following block to enable and configure speaker separation\n",
    "    # properties.diarization = swagger_client.DiarizationProperties(max_speakers=5, enabled=True)\n",
    "\n",
    "    # uncomment the following block to enable and configure language identification prior to transcription. Available modes are \"single\" and \"continuous\".\n",
    "    # properties.language_identification = swagger_client.LanguageIdentificationProperties(mode=\"single\", candidate_locales=[\"en-US\", \"ja-JP\"])\n",
    "\n",
    "    # Use base models for transcription. Comment this block if you are using a custom model.\n",
    "    transcription_definition = transcribe_from_single_blob(RECORDINGS_BLOB_URI, properties)\n",
    "\n",
    "    # Uncomment this block to use custom models for transcription.\n",
    "    # transcription_definition = transcribe_with_custom_model(client, RECORDINGS_BLOB_URI, properties)\n",
    "\n",
    "    # uncomment the following block to enable and configure language identification prior to transcription\n",
    "    # Uncomment this block to transcribe all files from a container.\n",
    "    # transcription_definition = transcribe_from_container(RECORDINGS_CONTAINER_URI, properties)\n",
    "\n",
    "    created_transcription, status, headers = api.transcriptions_submit_with_http_info(transcription=transcription_definition, api_version=API_VERSION)\n",
    "\n",
    "    # get the transcription Id from the location URI\n",
    "    transcription_id = headers[\"location\"].split(\"/\")[-1].split(\"?\")[0]\n",
    "\n",
    "    # Log information about the created transcription. If you should ask for support, please\n",
    "    # include this information.\n",
    "    logging.info(f\"Created new transcription with id '{transcription_id}' in region {SERVICE_REGION}\")\n",
    "\n",
    "    logging.info(\"Checking status.\")\n",
    "\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        # wait for 5 seconds before refreshing the transcription status\n",
    "        time.sleep(5)\n",
    "\n",
    "        transcription = api.transcriptions_get(transcription_id, api_version=API_VERSION)\n",
    "        logging.info(f\"Transcriptions status: {transcription.status}\")\n",
    "\n",
    "        if transcription.status in (\"Failed\", \"Succeeded\"):\n",
    "            completed = True\n",
    "\n",
    "        if transcription.status == \"Succeeded\":\n",
    "            if properties.destination_container_url is not None:\n",
    "                logging.info(\"Transcription succeeded. Results are located in your Azure Blob Storage.\")\n",
    "                break\n",
    "\n",
    "            pag_files = api.transcriptions_list_files(transcription_id, api_version=API_VERSION)\n",
    "            for file_data in _paginate(api, pag_files):\n",
    "                if file_data.kind != \"Transcription\":\n",
    "                    continue\n",
    "\n",
    "                audiofilename = file_data.name\n",
    "                results_url = file_data.links.content_url\n",
    "                results = requests.get(results_url)\n",
    "                logging.info(f\"Results for {audiofilename}:\\n{results.content.decode('utf-8')}\")\n",
    "        elif transcription.status == \"Failed\":\n",
    "            logging.info(f\"Transcription failed: {transcription.properties.error.message}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
