{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text, model_name=\"gpt-4\"):\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Usage example\n",
    "input_text = \"Azure OpenAI allows developers to integrate powerful LLMs...\"\n",
    "token_count = count_tokens(input_text)\n",
    "\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI API setup\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://<your-resource-name>.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"<your-api-key>\"\n",
    "\n",
    "def summarize_content(text):\n",
    "    try:\n",
    "        # Check token usage before making the call\n",
    "        token_count = count_tokens(text, model_name=\"gpt-4\")\n",
    "        max_token_limit = 8192\n",
    "\n",
    "        if token_count > max_token_limit:\n",
    "            raise ValueError(\"Input text exceeds token limit for GPT-4.\")\n",
    "\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-4\",  # Model selection\n",
    "            prompt=f\"Summarize the following text: {text}\",\n",
    "            max_tokens=200,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during summarization: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Azure OpenAI allows developers to integrate powerful LLMs for various tasks...\"\n",
    "summary = summarize_content(input_text)\n",
    "\n",
    "print(f\"Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# This example requires environment variables named \"LANGUAGE_KEY\" and \"LANGUAGE_ENDPOINT\"\n",
    "key = os.environ.get('AZURE_KEY')\n",
    "endpoint = os.environ.get('AZURE_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. This feature is provided as an API for developers. Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Example method for summarizing text\n",
    "def sample_extractive_summarization(client):\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import (\n",
    "        TextAnalyticsClient,\n",
    "        ExtractiveSummaryAction\n",
    "    ) \n",
    "\n",
    "    document = [\n",
    "        \"The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. \"\n",
    "        \"These sentences collectively convey the main idea of the document. This feature is provided as an API for developers. \" \n",
    "        \"They can use it to build intelligent solutions based on the relevant information extracted to support various use cases. \"\n",
    "        \"Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations. \"\n",
    "        \"It draws its strength from transfer learning across monolingual and harness the shared nature of languages to produce models of improved quality and efficiency. \"\n",
    "    ]\n",
    "\n",
    "    poller = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=4)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    document_results = poller.result()\n",
    "    for result in document_results:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            print(\"Summary extracted: \\n{}\".format(\n",
    "                \" \".join([sentence.text for sentence in extract_summary_result.sentences]))\n",
    "            )\n",
    "\n",
    "sample_extractive_summarization(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AnalyzeActionsType' from 'azure.ai.textanalytics' (c:\\Users\\firmansyah.atmojo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\azure\\ai\\textanalytics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtextanalytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextAnalyticsClient\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureKeyCredential\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtextanalytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnalyzeActionsType\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AnalyzeActionsType' from 'azure.ai.textanalytics' (c:\\Users\\firmansyah.atmojo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\azure\\ai\\textanalytics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import AnalyzeActionsType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(transcription):\n",
    "    \"\"\"\n",
    "    Summarize text using the latest Azure AI Text Analytics service.\n",
    "\n",
    "    Parameters:\n",
    "        transcription (str): The text to be summarized.\n",
    "        endpoint (str): The Azure endpoint URL.\n",
    "        key (str): The API key for the Azure AI Text Analysis service.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    # Authenticate the client\n",
    "    client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    try:\n",
    "        # Define the text document to be summarized\n",
    "        document = [{\"id\": \"1\", \"language\": \"en\", \"text\": transcription}]\n",
    "\n",
    "        # Perform the summarization using the analyze method\n",
    "        poller = client.begin_analyze_actions(\n",
    "            document,\n",
    "            actions=[{\"type\": AnalyzeActionsType.SUMMARIZE_TEXT}],\n",
    "        )\n",
    "        result = poller.result()\n",
    "\n",
    "        # Extract and return the summarized sentences\n",
    "        summarized_sentences = []\n",
    "        for action_result in result:\n",
    "            for doc_result in action_result:\n",
    "                if doc_result.kind == \"summarize\":\n",
    "                    summarized_sentences.extend([sentence.text for sentence in doc_result.sentences])\n",
    "\n",
    "        # Combine the summarized sentences\n",
    "        summarized_text = \" \".join(summarized_sentences)\n",
    "        return summarized_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\n",
    "        \"The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. \"\n",
    "        \"These sentences collectively convey the main idea of the document. This feature is provided as an API for developers. \" \n",
    "        \"They can use it to build intelligent solutions based on the relevant information extracted to support various use cases. \"\n",
    "        \"Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations. \"\n",
    "        \"It draws its strength from transfer learning across monolingual and harness the shared nature of languages to produce models of improved quality and efficiency. \"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'TextAnalyticsClient' object has no attribute 'extract_summary'\n"
     ]
    }
   ],
   "source": [
    "summarize_text(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Example method for summarizing text\n",
    "def sample_extractive_summarization(client, document):\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import (\n",
    "        TextAnalyticsClient,\n",
    "        ExtractiveSummaryAction\n",
    "    ) \n",
    "    poller = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=4)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    document_results = poller.result()\n",
    "    for result in document_results:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            print(\"Summary extracted: \\n{}\".format(\n",
    "                \" \".join([sentence.text for sentence in extract_summary_result.sentences]))\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. This feature is provided as an API for developers. Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "The global economy is expected to grow by 4% in 2025, driven by strong consumer demand and technological advancements. However, challenges such as inflation and geopolitical tensions remain. Economists suggest that policy measures will be crucial in navigating these uncertainties.\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient, ExtractiveSummaryAction\n",
    "\n",
    "\n",
    "key = os.environ.get('AZURE_KEY')\n",
    "endpoint = os.environ.get('AZURE_ENDPOINT')\n",
    "\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "def sample_extractive_summarization(client, document):\n",
    "    poller = client.begin_analyze_actions(\n",
    "        documents=[document],\n",
    "        actions=[ExtractiveSummaryAction(max_sentence_count=4)],\n",
    "    )\n",
    "\n",
    "    document_results = poller.result()\n",
    "    for result in document_results:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            summary = \" \".join([sentence.text for sentence in extract_summary_result.sentences])\n",
    "            print(\"Summary extracted: \\n{}\".format(summary))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = authenticate_client()\n",
    "    with open(\"sample_news.txt\", \"r\") as file:\n",
    "        document = file.read()\n",
    "    sample_extractive_summarization(client, document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries abstracted:\n",
      "The Chief Technology Officer of Azure AI Cognitive Services discusses Microsoft's commitment to advancing AI by integrating monolingual text, audio/visual sensory signals, and multilingual data, termed the XYZ-code, to create AI that better understands humans across different domains. This innovative approach aims to enable cross-domain transfer learning, spanning modalities and languages, drawing inspiration from human cognition. The team's efforts over the past five years have led to breakthroughs in conversational speech recognition, machine translation, conversational question answering, machine reading comprehension, and image captioning, achieving human-level performance on benchmarks. These advancements are seen as stepping stones toward a significant leap in AI capabilities, aspiring to develop multisensory and multilingual learning systems that mirror human learning processes. The ultimate goal is to ground the XYZ-code with external knowledge sources to enhance downstream AI tasks. This holistic strategy represents a pivotal shift in how Microsoft envisions the future of AI understanding and interaction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License. See License.txt in the project root for\n",
    "# license information.\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "FILE: sample_abstract_summary.py\n",
    "\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to submit text documents for abstractive text summarization.\n",
    "    Abstractive summarization is available as an action type through the begin_analyze_actions API.\n",
    "\n",
    "    Abstractive summarization generates a summary that may not use the same words as those in\n",
    "    the document, but captures the main idea.\n",
    "\n",
    "USAGE:\n",
    "    python sample_abstract_summary.py\n",
    "\n",
    "    Set the environment variables with your own values before running the sample:\n",
    "    1) AZURE_LANGUAGE_ENDPOINT - the endpoint to your Language resource.\n",
    "    2) AZURE_LANGUAGE_KEY - your Language subscription key\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sample_abstractive_summarization() -> None:\n",
    "    # [START abstract_summary]\n",
    "    import os\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "\n",
    "    document = [\n",
    "        \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, \"\n",
    "        \"human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive \"\n",
    "        \"Services, I have been working with a team of amazing scientists and engineers to turn this quest into a \"\n",
    "        \"reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of \"\n",
    "        \"human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the \"\n",
    "        \"intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint \"\n",
    "        \"representation to create more powerful AI that can speak, hear, see, and understand humans better. \"\n",
    "        \"We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, \"\n",
    "        \"spanning modalities and languages. The goal is to have pretrained models that can jointly learn \"\n",
    "        \"representations to support a broad range of downstream AI tasks, much in the way humans do today. \"\n",
    "        \"Over the past five years, we have achieved human performance on benchmarks in conversational speech \"\n",
    "        \"recognition, machine translation, conversational question answering, machine reading comprehension, \"\n",
    "        \"and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious \"\n",
    "        \"aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that \"\n",
    "        \"is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational \"\n",
    "        \"component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
    "    ]\n",
    "\n",
    "    poller = text_analytics_client.begin_abstract_summary(document)\n",
    "    abstract_summary_results = poller.result()\n",
    "    for result in abstract_summary_results:\n",
    "        if result.kind == \"AbstractiveSummarization\":\n",
    "            print(\"Summaries abstracted:\")\n",
    "            [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "        elif result.is_error is True:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                result.error.code, result.error.message\n",
    "            ))\n",
    "    # [END abstract_summary]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_abstractive_summarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "endpoint = os.environ[\"AZURE_ENDPOINT\"]\n",
    "key = os.environ[\"AZURE_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_summarization(document):\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "    \n",
    "    # Abstractive Summarization\n",
    "    poller = text_analytics_client.begin_abstract_summary([document])\n",
    "    abstract_summary_results = poller.result()\n",
    "    \n",
    "    print(\"Abstractive Summaries:\")\n",
    "    for result in abstract_summary_results:\n",
    "        if result.kind == \"AbstractiveSummarization\":\n",
    "            [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "        elif result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                result.error.code, result.error.message\n",
    "            ))\n",
    "    \n",
    "    # Extractive Summarization\n",
    "    poller = text_analytics_client.begin_extract_summary([document])\n",
    "    extract_summary_results = poller.result()\n",
    "    \n",
    "    print(\"Extractive Summary:\")\n",
    "    for result in extract_summary_results:\n",
    "        if result.kind == \"ExtractiveSummarization\":\n",
    "            print(\"Summary extracted: \\n{}\".format(\n",
    "                \" \".join([sentence.text for sentence in result.sentences])\n",
    "            ))\n",
    "        elif result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                result.error.code, result.error.message\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "At any given moment, turnaround coordinators for German airline Lufthansa CityLine have their eyes glued to monitors displaying more than half a dozen video feeds of airplanes parked at gates around the airport. The coordinators’ job is to ensure that the planes are unloaded, refueled, cleaned, restocked and reloaded so that every passenger reaches their destination safely, on time and with their luggage.\n",
    "\n",
    "            Minutes lost here or there in the turnaround process can add up, costing airlines millions of dollars a year. As many in the industry note, airplanes only make money while in the air.\n",
    "\n",
    "            “Think of a pitstop in a car race, and this is pretty much the same that happens in a turnaround for an aircraft,” said Philipp Grindemann, head of business development and project management for Lufthansa CityLine. “All the processes need to be on time, need to be fast, need to be lean.”\n",
    "\n",
    "            Lufthansa CityLine is a subsidiary of Lufthansa, one of the world’s major airline groups with a network that spans the globe. Lufthansa maintains hubs in Frankfurt and Munich, Germany. Lufthansa CityLine connects passengers with destinations around Europe to and from these hubs, flying more than 300 flights per day. Ontime arrivals and departures are essential for customer satisfaction and Lufthansa’s bottom line.\n",
    "\n",
    "            Outside of weather, delays stem from missteps during the tightly choreographed turnaround process. Like most industry players, Lufthansa CityLine relies on manual timestamps to understand when each step of the turnaround process starts and ends and uses that manual timestamp data to glean insights on where to make adjustments for faster, leaner turnarounds.\n",
    "\n",
    "            In a pilot phase, the airline partnered with zeroG, a Lufthansa Group consulting company founded by Lufthansa Systems to accelerate the tangible impact of artificial intelligence in operational and commercial processes at airlines around the world. One example is improving turnaround management with AI.\n",
    "\n",
    "            ZeroG’s Deep Turnaround solution leverages Azure Video Analyzer, a new offering from Microsoft that combines capabilities from Live Video Analytics and Azure Video Indexer. For Lufthansa, it generates automatic timestamps from the video feeds and issues alerts when the turnaround goes off script.\n",
    "\n",
    "            “With that transparency of Deep Turnaround – knowing when the caterer arrives, knowing when the bridge arrives in order to deboard the aircraft – the airline can steer the process and have much leaner processes than before,” said Manuel van Esch, lead consultant for zeroG.\n",
    "\n",
    "            For example, when a fuel truck arrives later than predicted, Deep Turnaround alerts the turnaround coordinators and other ground operations personnel. The alert kicks off a hunt for a solution that prevents a delay, such as dispatching a second fuel truck to the plane.\n",
    "\n",
    "            Applied AI Services\n",
    "            Azure Video Analyzer is among a handful of Azure Applied AI Services that Microsoft highlighted on Tuesday during Build, the company’s annual conference for developers. These services – Azure Video Analyzer, Azure Metrics Advisor, Azure Bot Service, Azure Cognitive Search, Azure Form Recognizer and Azure Immersive Reader – accelerate the development of scenario-specific AI solutions.\n",
    "\n",
    "            Azure Applied AI Services are built on top of AI models at the core of Azure AI products and services. That includes Azure Cognitive Services, which offer customizable AI models and tools for building AI solutions that help customers extract meaning from text, integrate speech into apps and services, identify and analyze content within images and videos, and make decisions.\n",
    "\n",
    "            Customers can also customize these services and extend them with their own custom models from Azure Machine Learning to meet the specific needs of their business.\n",
    "\n",
    "            Customers routinely tell Microsoft that while they see the potential of AI, building solutions are harder than they anticipated, said Eric Boyd, corporate vice president of Microsoft Azure AI in Redmond, Washington.\n",
    "\n",
    "            “The goal with Azure Applied AI Services is to provide a bit more packaging and structure to really accelerate the development of AI solutions for common business processes,” he said.\n",
    "\n",
    "            The Azure Video Analyzer service, for example, brings together Computer Vision from Azure Cognitive Services and an automatic captioning model along with capabilities for integrating existing closed circuit video feeds and video management systems, which make it easier for businesses to build video analytics solutions.\n",
    "\n",
    "            Microsoft created the Azure Applied AI Services category to target common business scenarios that Boyd’s Azure AI team has seen customers repeatedly build from scratch. For example, Azure Form Recognizer builds on optical character recognition, a computer vision technology that recognizes text and is key to many business solutions from reading receipts to pulling data from intake forms.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstractive Summaries:\n",
      "Lufthansa CityLine, a subsidiary of Lufthansa, relies on turnaround coordinators to manage the tightly scheduled process of unloading, refueling, cleaning, restocking, and reloading aircraft to ensure timely departures and arrivals. The coordinators monitor multiple video feeds, but manual timestamping is currently used to track process steps, which can be adjusted to improve efficiency. To enhance turnaround management, Lufthansa CityLine partnered with zeroG, a consulting company, and implemented Deep Turnaround using Microsoft's Azure Video Analyzer. This technology provides automatic timestamps, alerts for deviations, and helps steer processes to prevent delays, as demonstrated when a late-arriving fuel truck triggers an alert for immediate resolution. Azure Applied AI Services, highlighted by Microsoft, offer structured development of AI solutions for common business processes, including video analytics, which Lufthansa leverages for operational transparency and leaner processes. The integration of AI into their operations exemplifies the airline's commitment to customer satisfaction and cost-effective operations.\n",
      "\n",
      "Extractive Summary:\n",
      "Summary extracted: \n",
      "Minutes lost here or there in the turnaround process can add up, costing airlines millions of dollars a year. Azure Video Analyzer is among a handful of Azure Applied AI Services that Microsoft highlighted on Tuesday during Build, the company’s annual conference for developers. These services – Azure Video Analyzer, Azure Metrics Advisor, Azure Bot Service, Azure Cognitive Search, Azure Form Recognizer and Azure Immersive Reader – accelerate the development of scenario-specific AI solutions.\n"
     ]
    }
   ],
   "source": [
    "sample_summarization(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_SERVICE_REGION = os.getenv(\"AZURE_SERVICE_REGION\")\n",
    "AZURE_KEY = os.getenv(\"AZURE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'601c0ddb54cd40709ed8efe586d8ed42'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AZURE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create batch transcription job: 201\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Azure Speech Service configuration\n",
    "transcription_endpoint = f\"https://{AZURE_SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions\"\n",
    "\n",
    "# Audio files in Azure Blob Storage\n",
    "audio_files = [\n",
    "    \"https://smlbird.blob.core.windows.net/input/temp_audio.wav\"\n",
    "]\n",
    "\n",
    "# Create transcription job\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": AZURE_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "body = {\n",
    "    \"contentUrls\": audio_files,\n",
    "    \"locale\": \"en-US\",\n",
    "    \"displayName\": \"Batch Transcription Example\"\n",
    "}\n",
    "\n",
    "response = requests.post(transcription_endpoint, headers=headers, data=json.dumps(body))\n",
    "if response.status_code == 202:\n",
    "    print(\"Batch transcription job created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create batch transcription job: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self': 'https://southeastasia.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/63454d8a-d0c3-4feb-a12f-47343b9e231a',\n",
       " 'displayName': 'Batch Transcription Example',\n",
       " 'locale': 'en-US',\n",
       " 'createdDateTime': '2025-01-21T04:20:24Z',\n",
       " 'lastActionDateTime': '2025-01-21T04:20:24Z',\n",
       " 'status': 'NotStarted',\n",
       " 'model': {'self': 'https://southeastasia.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/10e98dd4-3d36-4296-b383-3508d63b1e0b'},\n",
       " 'links': {'files': 'https://southeastasia.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/63454d8a-d0c3-4feb-a12f-47343b9e231a/files'},\n",
       " 'properties': {'diarizationEnabled': False,\n",
       "  'wordLevelTimestampsEnabled': False,\n",
       "  'displayFormWordLevelTimestampsEnabled': False,\n",
       "  'channels': [0, 1],\n",
       "  'punctuationMode': 'DictatedAndAutomatic',\n",
       "  'profanityFilterMode': 'Masked'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch transcription job created successfully.\n",
      "Best Transcription: Three years ago a one bedroom off plant has been 150, so now it's 215 after wow, three years and something Yes, yes, the land prices are increasing, the construction prices are increasing. If we want to resell also, they are making the profit. Yeah. So if you resell what? Sorry, what land title do they get? We only build on pink commercial zoning. This is what you mean or what? I know if they sell the land, yes, or the house, yes. Freehold. No, no, no, not freehold. Leasehold. No, No. So we transfer from the owner, it transfers to the new buyer. Yes. Leaseholds still still leasehold. Yeah, exactly. With the remaining years now we're going to go, right. OK. Rain are shining. No. Maybe you will go. Maybe you'll visit your son in Spain and pass by. If you have so many friends. We can go right here now and we're going to look over the fence and how I'll show you where, where there's constructions.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "transcription_endpoint = f\"https://{AZURE_SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions\"\n",
    "\n",
    "# Audio files in Azure Blob Storage\n",
    "audio_files = [\n",
    "    \"https://smlbird.blob.core.windows.net/input/temp_audio.wav\"\n",
    "]\n",
    "\n",
    "# Create transcription job\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": AZURE_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "body = {\n",
    "    \"contentUrls\": audio_files,\n",
    "    \"locale\": \"en-US\",\n",
    "    \"displayName\": \"Batch Transcription Example\"\n",
    "}\n",
    "\n",
    "response = requests.post(transcription_endpoint, headers=headers, data=json.dumps(body))\n",
    "if response.status_code == 201:\n",
    "    print(\"Batch transcription job created successfully.\")\n",
    "    job_location = response.headers[\"Location\"]\n",
    "else:\n",
    "    print(f\"Failed to create batch transcription job: {response.status_code}\")\n",
    "    print(\"Response:\", response.json())\n",
    "    exit()\n",
    "\n",
    "# Check transcription job status\n",
    "def check_transcription_status(job_location):\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": AZURE_KEY\n",
    "    }\n",
    "    response = requests.get(job_location, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Wait for the transcription job to complete\n",
    "while True:\n",
    "    job_status = check_transcription_status(job_location)\n",
    "    status = job_status[\"status\"]\n",
    "    if status in [\"Succeeded\", \"Failed\"]:\n",
    "        break\n",
    "    #print(f\"Job status: {status}. Waiting for 30 seconds...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "# Retrieve transcription results and save to a variable\n",
    "transcription_results = []\n",
    "if status == \"Succeeded\":\n",
    "    files_url = job_status[\"links\"][\"files\"]\n",
    "    files_response = requests.get(files_url, headers=headers)\n",
    "    files = files_response.json()\n",
    "    for file in files[\"values\"]:\n",
    "        result_url = file[\"links\"][\"contentUrl\"]\n",
    "        result_response = requests.get(result_url)\n",
    "        result_content = result_response.json()\n",
    "        transcription_results.append(result_content)\n",
    "else:\n",
    "    print(\"Transcription job failed.\")\n",
    "\n",
    "# Function to extract the best transcription result\n",
    "def get_best_transcription(transcription_result):\n",
    "    # Extract the 'combinedRecognizedPhrases' list\n",
    "    phrases = transcription_result.get('combinedRecognizedPhrases', [])\n",
    "    \n",
    "    # Check if there are any phrases\n",
    "    if not phrases:\n",
    "        return None\n",
    "    \n",
    "    # Extract the first phrase (assuming it's the best one)\n",
    "    best_phrase = phrases[0]\n",
    "    \n",
    "    # Return the 'display' transcription as it's usually the most readable\n",
    "    return best_phrase.get('display', '')\n",
    "\n",
    "# Example of accessing the first transcription result\n",
    "if transcription_results:\n",
    "    first_result = transcription_results[0]\n",
    "    best_transcription = get_best_transcription(first_result)\n",
    "    print(\"Best Transcription:\", best_transcription)\n",
    "\n",
    "# Now the best transcription is saved in the 'best_transcription' variable\n",
    "\n",
    "# Note: Replace 'YourSpeechKey', 'YourServiceRegion', and the URLs in 'audio_files' with your actual Azure credentials and audio file URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Three years ago a one bedroom off plant has been 150, so now it's 215 after wow, three years and something Yes, yes, the land prices are increasing, the construction prices are increasing. If we want to resell also, they are making the profit. Yeah. So if you resell what? Sorry, what land title do they get? We only build on pink commercial zoning. This is what you mean or what? I know if they sell the land, yes, or the house, yes. Freehold. No, no, no, not freehold. Leasehold. No, No. So we transfer from the owner, it transfers to the new buyer. Yes. Leaseholds still still leasehold. Yeah, exactly. With the remaining years now we're going to go, right. OK. Rain are shining. No. Maybe you will go. Maybe you'll visit your son in Spain and pass by. If you have so many friends. We can go right here now and we're going to look over the fence and how I'll show you where, where there's constructions.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
